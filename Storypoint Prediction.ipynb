{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storypoint Prediction: Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, validation_curve\n",
    "from trainer import GridSearchCVTrainer\n",
    "\n",
    "project_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    plt.figure()        # Create new figure\n",
    "    plt.title(title)    # Set title of the figure\n",
    "    \n",
    "    # Set y-axis limits: ylim=(min, max)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)  \n",
    "        \n",
    "    plt.xlabel(\"Training examples\")  # Set x-axis label\n",
    "    plt.ylabel(\"Score\")               # Set y-axis label\n",
    "    \n",
    "    # Generate learning curve data\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)  # Calculate mean of training scores\n",
    "    train_scores_std = np.std(train_scores, axis=1)    # Calculate standard deviation of training scores\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)    # Calculate mean of test scores\n",
    "    test_scores_std = np.std(test_scores, axis=1)      # Calculate standard deviation of test scores\n",
    "    \n",
    "    plt.grid()  # Display grid\n",
    "    \n",
    "    # Fill the area between the mean training score and the mean +/- std training score\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    \n",
    "    # Fill the area between the mean test score and the mean +/- std test score\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # Plot mean training score as points\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    # Plot mean test score as points\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")  # Display legend\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, title, X, y, param_name, param_range,\n",
    "                          y_lim=None, cv=10, n_jobs=-1):\n",
    "    train_scores, val_scores = validation_curve(estimator=estimator, X=X, y=y, \n",
    "                                                 param_name=param_name, param_range=param_range, \n",
    "                                                 cv=cv, n_jobs=n_jobs,\n",
    "                                                 scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Calculate mean and standard deviation of training and validation scores\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    tran_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    print(val_mean)\n",
    "    \n",
    "    # Plot train scores\n",
    "    plt.plot(param_range, train_mean, color='r', marker='o', markersize=5, label='Training score')\n",
    "    plt.fill_between(param_range, train_mean + tran_std, train_mean - tran_std, alpha=0.15, color='r')\n",
    "    \n",
    "    # Plot validation scores\n",
    "    plt.plot(param_range, val_mean, color='g', linestyle='--', marker='s', markersize=5, label='Validation score')\n",
    "    plt.fill_between(param_range, val_mean + val_std, val_mean - val_std, alpha=0.15, color='g')\n",
    "    \n",
    "    plt.title(title)        # Set title of the plot\n",
    "    plt.grid()              # Display grid\n",
    "    plt.xscale('log')       # Set x-axis scale to log\n",
    "    plt.legend(loc='best')  # Display legend\n",
    "    plt.xlabel('Parameter') # Set x-axis label\n",
    "    plt.ylabel('Score')     # Set y-axis label\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    if y_lim != None:\n",
    "        plt.ylim(y_lim)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, X_test, y_test, y_logscale=False, save_directory=None):\n",
    "    y_pred = model.predict(X_test)\n",
    "    if(y_logscale):\n",
    "        y_pred = np.exp(y_pred)\n",
    "        \n",
    "    lines = [model_name + '\\'s evaluation results:']\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred) \n",
    "    rmse = np.sqrt(mse) \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    lines.append(f' - Mean squared error:      {mse:.2f}')\n",
    "    lines.append(f' - Root mean squared error: {rmse:.2f}')\n",
    "    lines.append(f' - Mean absolute error:     {mae:.2f}')\n",
    "    lines.append(f' - R2 error:                {r2:.2f}')\n",
    "    \n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    lines.append(f' - F1 score:                {f1:.2f}')\n",
    "    lines.append(f' - Precision:               {precision:.2f}')\n",
    "    lines.append(f' - Recall:                  {recall:.2f}')\n",
    "    lines.append(f' - Accuracy:                {accuracy:.2f}')\n",
    "    lines.append('-------------------------------------------------')\n",
    "    lines.append('')\n",
    "    \n",
    "    # Save to file\n",
    "    \n",
    "    if(save_directory != None):\n",
    "        filename = save_directory + project_name + '.txt'\n",
    "        directory = os.path.dirname(filename)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        with open(filename, 'a') as f:\n",
    "            for line in lines:\n",
    "                print(line)\n",
    "                f.write(line + '\\n')\n",
    "    else:\n",
    "        for line in lines:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for numpy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set random seed for random\n",
    "random.seed(42)\n",
    "\n",
    "# Set random seed for os\n",
    "os.environ['PYTHONHASHSEED'] = '42'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Bag of Words preprocess approach. I will use 2 CountVectorizer from sklearn to change title and description to two 2 vectors and then concatenate them together. In the rest of this notebook, I will use cross-validation instead hold-out. Therefore, I will join the validation set with training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: I don't add the length of description (and the title) because it has a big deviation which may cause noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and remove NaN value\n",
    "\n",
    "\n",
    "data_train = pd.concat([pd.read_csv('data/' + project_name + '/' + project_name + '_train.csv'),\n",
    "                       pd.read_csv('data/' + project_name + '/' + project_name + '_valid.csv')])\n",
    "data_test = pd.read_csv('data/' + project_name + '/' + project_name + '_test.csv')\n",
    "\n",
    "data_train['description'].replace(np.nan, '', inplace=True)\n",
    "data_test['description'].replace(np.nan, '', inplace=True)\n",
    "\n",
    "# Vectorize title\n",
    "title_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "title_vectorizer.fit(pd.concat([data_train['title'], data_test['title']]))\n",
    "\n",
    "# Vectorize description\n",
    "description_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "description_vectorizer.fit(pd.concat([data_train['description'], data_test['description']]))\n",
    "\n",
    "\n",
    "X_train = hstack([title_vectorizer.transform(data_train['title']).astype(float),\n",
    "                  description_vectorizer.transform(data_train['description']).astype(float),\n",
    "                  data_train['title'].apply(lambda x : len(x)).to_numpy().reshape(-1, 1),\n",
    "                  data_train['description'].apply(lambda x : len(x)).to_numpy().reshape(-1, 1)\n",
    "                ])\n",
    "\n",
    "y_train = data_train['storypoint'].to_numpy().astype(float)\n",
    "\n",
    "X_test = hstack([title_vectorizer.transform(data_test['title']).astype(float),\n",
    "                  description_vectorizer.transform(data_test['description']).astype(float),\n",
    "                  data_test['title'].apply(lambda x : len(x)).to_numpy().reshape(-1, 1),\n",
    "                  data_test['description'].apply(lambda x : len(x)).to_numpy().reshape(-1, 1)\n",
    "                ])\n",
    "\n",
    "y_test = data_test['storypoint'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check training dataset\\'shape:', X_train.shape, y_train.shape)\n",
    "print('Check testing dataset\\'shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use log-scale the label to get a normal distribution of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params-grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    'alpha': [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\n",
    "    'l1_ratio': [.0, .2, .4, .6, .8, 1],\n",
    "    'max_iter': [10**5],\n",
    "    'random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCVTrainer(name='Elastic Net', model=ElasticNet(), param_grid=dict_param, cv=5, n_jobs=5)\n",
    "gridsearch.load_if_exists()\n",
    "gridsearch.fit(X_train, y_train_log)\n",
    "\n",
    "elastic_model = gridsearch.best_estimator_\n",
    "elastic_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(elastic_model, 'Elastic Net model', X_test, y_test, y_logscale=True, save_directory='results/BoW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    'C': [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\n",
    "    'gamma': np.logspace(-9, 3, 13),\n",
    "    'kernel': ['rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCVTrainer(name=\"Support Vector Regressor\",model=SVR(), param_grid=dict_param, cv=5, n_jobs=5)\n",
    "grid_search.load_if_exists()\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "svr_model = grid_search.best_estimator_\n",
    "svr_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(svr_model, 'SVR model', X_test, y_test, y_logscale=True, save_directory='results/BoW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    'max_depth' : [1000, 2000, 5000],\n",
    "    'min_samples_split': [25, 200, 1000],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'max_features': [50, 100, 200],\n",
    "    'n_estimators': [1024],\n",
    "    'random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCVTrainer(name=\"Random Forest Regressor\", \n",
    "                                  model=RandomForestRegressor(), \n",
    "                                  param_grid=dict_param, cv = 5, n_jobs=5)\n",
    "grid_search.load_if_exists()\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "rfr_model = grid_search.best_estimator_\n",
    "rfr_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rfr_model, 'Random Forest model', X_test, y_test, y_logscale=True, save_directory='results/BoW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    'eta' : np.linspace(0.01, 0.2, 3),\n",
    "    'gamma': np.logspace(-2, 2, 5),\n",
    "    'max_depth': np.asarray([3, 5, 7, 9]).tolist(),\n",
    "    'min_child_weight': np.logspace(-2, 2, 5),\n",
    "    'subsample': np.asarray([0.5, .1]),\n",
    "    'reg_alpha': np.asarray([0.0, 0.05]),\n",
    "    'n_estimators': np.asarray([10, 20, 50, 100]).tolist(),\n",
    "    'random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCVTrainer(name='XGBoost Regressor',model=XGBRegressor(), param_grid=dict_param, cv = 5, n_jobs=5)\n",
    "grid_search.load_if_exists()\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "xgb_model = grid_search.best_estimator_\n",
    "xgb_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(xgb_model, 'XGBoost Regressor model', X_test, y_test, y_logscale=True, save_directory='results/BoW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    'n_estimator': [10, 20, 50, 100, 200, 500],\n",
    "    'max_depth': np.asarray([5, 7, 9, 11, 13]).tolist(),\n",
    "    'num_leaves': ((np.power(2, np.asarray([5, 7, 9, 11, 13])) - 1) * (0.55 + (0.65 - 0.55) * np.random.rand(5))).astype(int).tolist(),\n",
    "    'min_data_in_leaf': np.linspace(100, 1000, 4).astype(int).tolist(),\n",
    "    'feature_fraction': np.linspace(0.6, 1, 3),\n",
    "    'bagging_fraction': np.linspace(0.6, 1, 3),\n",
    "    'learning_rate': [0.01],\n",
    "    'verbose': [-1],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "def custom_sampler(param_grid):\n",
    "    for params in ParameterSampler(param_grid, n_iter=1e9):\n",
    "        range_num_leaves = ((0.5 * (2**params['max_depth'] - 1)), (0.7 * (2**params['max_depth']) - 1))\n",
    "        if(range_num_leaves[0] <= params['num_leaves'] <= range_num_leaves[1]):\n",
    "            for key, value in params.items():\n",
    "                params[key] = [value]\n",
    "            yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCVTrainer(name='LightGBM Regressor', model=LGBMRegressor(), \n",
    "                                param_grid=list(custom_sampler(dict_param)), cv = 5, n_jobs=2)\n",
    "grid_search.load_if_exists()\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "lgbmr_model = grid_search.best_estimator_\n",
    "lgbmr_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lgbmr_model, 'LightGBM regressor model', X_test, y_test, y_logscale=True,  save_directory='results/BoW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmr_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define component models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'trainer_checkpoint_data/'\n",
    "with open(directory + 'elastic net_checkpoint.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    elastic_model = ElasticNet(**data['best_params'])\n",
    "\n",
    "with open(directory + 'support vector regressor_checkpoint.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    svr_model = SVR(**data['best_params'])\n",
    "    \n",
    "with open(directory + 'random forest regressor_checkpoint.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    rfr_model = RandomForestRegressor(**data['best_params'], n_jobs=-1)\n",
    "    \n",
    "with open(directory + 'xgboost regressor_checkpoint.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    xgb_model = XGBRegressor(**data['best_params'])\n",
    "\n",
    "with open(directory + 'lightgbm regressor_checkpoint.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    lgbmr_model = LGBMRegressor(**data['best_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define blended model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(xgb_model, lgbmr_model, svr_model, elastic_model, rfr_model),\n",
    "                                meta_regressor=xgb_model,\n",
    "                                use_features_in_secondary=True, n_jobs=-1)\n",
    "stack_gen.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(stack_gen, 'Stacking model', X_test, y_test, y_logscale=True, save_directory='results/BoW/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
